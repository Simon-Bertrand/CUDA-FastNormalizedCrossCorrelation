{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcac6c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install https://github.com/Simon-Bertrand/FastCrossCorr-PyTorch/archive/main.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5749bc1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_crosscorr\n",
    "import torch_bidimcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ffcc286",
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W = 1024,1024\n",
    "h,w = 256,256\n",
    "\n",
    "a = 5* torch.rand(8,1,H, H, device='cuda').to(torch.double)\n",
    "b = 5* torch.rand(8,1,h, w, device='cuda').to(torch.double)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "fdbb7d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cc = torch_crosscorr.FastNormalizedCrossCorrelation(\"corr\", \"fft\", padding=\"valid\", center=False, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "309cf58a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cc = torch_bidimcc.fft_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f5ddd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_cc_ans = old_cc(a,b)\n",
    "new_cc_ans = new_cc(a,b)\n",
    "assert torch.allclose(old_cc_ans, new_cc_ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80926acc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward pass close? True\n",
      "Gradients for 'a' close? True\n",
      "Gradients for 'b' close? True\n"
     ]
    }
   ],
   "source": [
    "# 1. Create fresh distinct inputs for each method to ensure no gradient accumulation interference\n",
    "a1 = a.clone().detach().requires_grad_(True)\n",
    "b1 = b.clone().detach().requires_grad_(True)\n",
    "a2 = a.clone().detach().requires_grad_(True)\n",
    "b2 = b.clone().detach().requires_grad_(True)\n",
    "# 2. Run Forward Passes\n",
    "res_old = old_cc(a1, b1)\n",
    "res_new = new_cc(a2, b2)\n",
    "# 3. Check Forward consistency first (sanity check)\n",
    "print(f\"Forward pass close? {torch.allclose(res_old, res_new, atol=1e-4)}\")\n",
    "# 4. Run Backward Passes\n",
    "res_old.sum().backward()\n",
    "res_new.sum().backward()\n",
    "# 5. Compare Gradients\n",
    "grads_a_close = torch.allclose(a1.grad, a2.grad, atol=1e-2)\n",
    "grads_b_close = torch.allclose(b1.grad, b2.grad, atol=1e-2)\n",
    "print(f\"Gradients for 'a' close? {grads_a_close}\")\n",
    "print(f\"Gradients for 'b' close? {grads_b_close}\")\n",
    "if not grads_a_close:\n",
    "    print(f\"Max diff 'a': {(a1.grad - a2.grad).abs().max().item()}\")\n",
    "if not grads_b_close:\n",
    "    print(f\"Max diff 'b': {(b1.grad - b2.grad).abs().max().item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6900f212",
   "metadata": {},
   "source": [
    "# Speed comparison for raw 2D cross-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2b923f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.8 ms ± 75.6 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit old_cc(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "134e0fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.7 ms ± 1.14 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit new_cc(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3286fe",
   "metadata": {},
   "source": [
    "# Memory usage for raw 2D cross-correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8ab2c426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak GPU memory usage: 1236.22 MB\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "old_cc(a, b)\n",
    "peak = torch.cuda.max_memory_allocated()\n",
    "\n",
    "print(f\"Peak GPU memory usage: {peak / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "350d4c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak GPU memory usage: 896.08 MB\n"
     ]
    }
   ],
   "source": [
    "torch.cuda.reset_peak_memory_stats()\n",
    "new_cc(a, b)\n",
    "peak = torch.cuda.max_memory_allocated()\n",
    "\n",
    "print(f\"Peak GPU memory usage: {peak / 1024**2:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510dc186",
   "metadata": {},
   "source": [
    "# Results : \n",
    "Could increase a bit the speed for double and reduce the memory usage in comparison with https://github.com/Simon-Bertrand/FastCrossCorr-PyTorch\n",
    "\n",
    "The speed increase is not as good as expected because the bottleneck is, for both case, the same cuFFT algorithm under the hood. The new_cc method processes ~1.5x fewer pixels (valid padding), which aligns well with the ~1.3x - 1.4x speedup we see (factoring in some fixed overheads). \n",
    "This means that the new_cc method is faster and less memory-hungry than the old_cc method but the difference is not significant."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
